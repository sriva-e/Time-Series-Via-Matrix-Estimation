{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "#\n",
    "# Utility functions\n",
    "#\n",
    "######################################################\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import copy\n",
    "from numpy.linalg import qr  as qr\n",
    "\n",
    "class tsUtils:\n",
    "    \n",
    "    def updateSVD(D, uk, sk, vk):\n",
    "        vk = vk.T\n",
    "        m = vk.shape[1]\n",
    "        d = m+D.shape[1]\n",
    "        D_k = np.dot(np.dot(D.T, uk), np.diag(1 / sk))\n",
    "        vkh = np.zeros([len(sk), d])\n",
    "        vkh[:, :m] = vk\n",
    "        vkh[:, m:d] = D_k.T\n",
    "\n",
    "        return uk, sk, vkh.T\n",
    "\n",
    "\n",
    "    def updateSVD2(D, uk, sk, vk):\n",
    "        vk = vk.T\n",
    "        k,m = vk.shape\n",
    "        n,p = D.shape\n",
    "        # memory intensive? nxn dot nxp\n",
    "        D_h = np.dot(np.eye(n)- np.dot(uk,uk.T),D)\n",
    "        # Qr of n X p matrix ~ relatively easy\n",
    "        Qd,Rd = qr(D_h)\n",
    "\n",
    "        A_h = np.zeros([p+k,p+k])\n",
    "        A_h[:k,:k] = np.diag(sk)\n",
    "        A_h[:k,k:k+p] = np.dot(uk.T,D)\n",
    "        A_h[k:k+p, k:k+p] = Rd\n",
    "        # SVD of p+k X p+k matrix ~ relatively easy\n",
    "        ui, si, vi = np.linalg.svd(A_h, full_matrices=False)\n",
    "        uk_h = ui[:,:k]\n",
    "        sk_h = si[:k]\n",
    "        vk_h = vi[:k,:]\n",
    "\n",
    "        sk_u = sk_h\n",
    "\n",
    "        # matirx mult. n X (k+p) by (k+p) X k\n",
    "        #uk_u = np.dot(np.concatenate((uk,Qd),1),uk_h)\n",
    "        uk_u = np.zeros([n, k+p])\n",
    "        uk_u[:,:k] = uk\n",
    "        uk_u[:, k:k+p] = Qd\n",
    "        uk_u = np.dot(uk_u,uk_h)\n",
    "\n",
    "        vk_u = np.zeros([m+p,k+p])\n",
    "        vk_u[:m,:k] = vk.T\n",
    "        vk_u[m:m+p, k:k+p] = np.eye(p)\n",
    "\n",
    "        vk_2 = np.dot(vk_u,vk_h.T)\n",
    "        return uk_u, sk_u, vk_2\n",
    "\n",
    "    def arrayToMatrix(npArray, nRows, nCols):\n",
    "\n",
    "        if (type(npArray) != np.ndarray):\n",
    "            raise Exception('npArray is required to be of type np.ndarray')\n",
    "\n",
    "        if (nRows * nCols != len(npArray)):\n",
    "            raise Exception('(nRows * nCols) must equal the length of npArray')\n",
    "\n",
    "        return np.reshape(npArray, (nCols, nRows)).T\n",
    "\n",
    "\n",
    "    def matrixFromSVD(sk, Uk, Vk, probability=1.0):\n",
    "        return (1.0/probability) * np.dot(Uk, np.dot(np.diag(sk), Vk.T))\n",
    "\n",
    "    def pInverseMatrixFromSVD(sk, Uk, Vk, probability=1.0):\n",
    "        s = copy.deepcopy(sk)\n",
    "        for i in range(0, len(s)):\n",
    "            if (s[i] > 0.0):\n",
    "                s[i] = 1.0/s[i]\n",
    "\n",
    "        p = 1.0/probability\n",
    "        return tsUtils.matrixFromSVD(s, Vk, Uk, probability=p)\n",
    "\n",
    "\n",
    "    def rmse(array1, array2):\n",
    "        return np.sqrt(mean_squared_error(array1, array2))\n",
    "\n",
    "\n",
    "    def rmseMissingData(array1, array2):\n",
    "\n",
    "        if (len(array1) != len(array2)):\n",
    "            raise Exception('lengths of array1 and array2 must be the same.')\n",
    "\n",
    "        subset1 = []\n",
    "        subset2 = []\n",
    "        for i in range(0, len(array1)):\n",
    "            if np.isnan(array1[i]):\n",
    "                subset1.append(array1[i])\n",
    "                subset2.append(array2[i])\n",
    "\n",
    "        return tsUtils.rmse(subset1, subset2)\n",
    "\n",
    "\n",
    "    def normalize(array, max, min):\n",
    "\n",
    "        diff = 0.5*(min + max)\n",
    "        div = 0.5 * (max - min)\n",
    "\n",
    "        array = (array - diff)/div\n",
    "        return array\n",
    "\n",
    "    def unnormalize(array, max, min):\n",
    "\n",
    "        diff = 0.5*(min + max)\n",
    "        div = 0.5*(max - min)\n",
    "\n",
    "        array = (array *div) + diff\n",
    "        return array\n",
    "\n",
    "\n",
    "    def randomlyHideValues(array, pObservation):\n",
    "\n",
    "        count = 0\n",
    "        for i in range(0, len(array)):\n",
    "            if (np.random.uniform(0, 1) > pObservation):\n",
    "                array[i] = np.nan\n",
    "                count +=1 \n",
    "\n",
    "        p_obs = float(count)/float(len(array))\n",
    "        return (array, 1.0 - p_obs)\n",
    "\n",
    "# chooses rows of the matrix according to pObservationRow\n",
    "# hide stretches of data with the longestStretch being the max entries hidden in a row\n",
    "# gap should ideally be the number of columns of the matrix this array will be converted in to\n",
    "    def randomlyHideConsecutiveEntries(array, pObservationRow, longestStretch, gap):\n",
    "\n",
    "        n = len(array)\n",
    "        valuesToHide = int((1.0 - pObservationRow) * n)\n",
    "\n",
    "        count = 0\n",
    "        countStart = 0\n",
    "        i = 0\n",
    "        while (i < n):\n",
    "            # decide if this point is the start of a randomly missing run\n",
    "            if (np.random.uniform(0, 1) > pObservationRow):\n",
    "                countStart +=1\n",
    "\n",
    "                # now decide how many consecutive values go missing and where to start\n",
    "                toHide = longestStretch #int(np.random.uniform(0, 1) * longestStretch)\n",
    "                startingIndex = i + int(np.random.uniform(0, 1) * (gap - toHide))\n",
    "\n",
    "                if (toHide + startingIndex >  (i + gap)):\n",
    "                    toHide = (i + gap) - startingIndex\n",
    "\n",
    "                array[startingIndex: startingIndex + toHide] = np.nan * np.zeros(toHide)\n",
    "                \n",
    "                count += toHide\n",
    "\n",
    "                valuesToHide -= toHide\n",
    "\n",
    "                if (valuesToHide <= 0):\n",
    "                    break\n",
    "\n",
    "            # ensure there is some space between consecutive runs\n",
    "            i += gap\n",
    "\n",
    "        p_obs = float(count)/float(n)\n",
    "\n",
    "        return (array, 1.0 - p_obs)\n",
    "\n",
    "\n",
    "    # following is taken from: https://stackoverflow.com/questions/6518811/interpolate-nan-values-in-a-numpy-array\n",
    "    def nanInterpolateHelper(array):\n",
    "        \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "        Input:\n",
    "            - y, 1d numpy array with possible NaNs\n",
    "        Output:\n",
    "            - nans, logical indices of NaNs\n",
    "            - index, a function, with signature indices= index(logical_indices),\n",
    "            to convert logical indices of NaNs to 'equivalent' indices\n",
    "        Example:\n",
    "            >>> # linear interpolation of NaNs\n",
    "            >>> nans, x= nan_helper(y)\n",
    "            >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "        \"\"\"\n",
    "        (nans, x) = (np.isnan(array), lambda z: z.nonzero()[0])\n",
    "        array[nans] = np.interp(x(nans), x(~nans), array[~nans])\n",
    "        return array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVD Wrapper\n",
    "class SVD:\n",
    "\n",
    "    def __init__(self, matrix, method='numpy'):\n",
    "        if (type(matrix) != np.ndarray):\n",
    "            raise Exception('SVDWrapper required matrix to be of type np.ndarray')\n",
    "\n",
    "        self.methods = ['numpy']\n",
    "\n",
    "        self.matrix = matrix\n",
    "        self.U = None\n",
    "        self.V = None\n",
    "        self.s = None\n",
    "        (self.N, self.M) = np.shape(matrix)\n",
    "\n",
    "        if (method not in self.methods):\n",
    "            print(\"The methods specified (%s) if not a valid option. Defaulting to numpy.linalg.svd\" %method)\n",
    "            self.method = 'numpy'\n",
    "\n",
    "        else:\n",
    "            self.method = method\n",
    "\n",
    "    # perform the SVD decomposition\n",
    "    # method will set the self.U and self.V singular vector matrices and the singular value array: self.s\n",
    "    # U, s, V can then be access separately as attributed of the SVDWrapper class\n",
    "    def decompose(self):\n",
    "        # default is numpy's linear algebra library\n",
    "        (self.U, self.s, self.V) = np.linalg.svd(self.matrix, full_matrices=False)\n",
    "\n",
    "        # correct the dimensions of V\n",
    "        self.V = self.V.T\n",
    "\n",
    "    # get the top K singular values and corresponding singular vector matrices\n",
    "    def decomposeTopK(self, k):\n",
    "\n",
    "        # if k is 0 or less, just return empty arrays\n",
    "        if (k < 1):\n",
    "            return ([], [], [])\n",
    "\n",
    "        # if k > the max possible singular values, set it to be that value\n",
    "        elif (k > np.min([self.M, self.N])):\n",
    "            k = np.min([self.M, self.N])\n",
    "\n",
    "        if ((self.U is None) | (self.V is None) | (self.s is None)):\n",
    "            self.decompose() # first perform the full decomposition\n",
    "\n",
    "        sk = self.s[0:k]\n",
    "        Uk = self.U[:, 0:k]\n",
    "        Vk = self.V[:, 0:k]\n",
    "\n",
    "        return (sk, Uk, Vk)\n",
    "\n",
    "    # get the matrix reconstruction using top K singular values\n",
    "    # if returnMatrix = True, then return the actual matrix, else return sk, Uk, Vk\n",
    "    def reconstructMatrix(self, kSingularValues, returnMatrix=False):\n",
    "\n",
    "        (sk, Uk, Vk) = self.decomposeTopK(kSingularValues)\n",
    "        if (returnMatrix == True):\n",
    "            return tsUtils.matrixFromSVD(sk, Uk, Vk)\n",
    "        else:\n",
    "            return (sk, Uk, Vk)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALS Wrapper\n",
    "######################################################\n",
    "#\n",
    "# Alternating Least Squares\n",
    "#\n",
    "######################################################\n",
    "import time\n",
    "class ALS:\n",
    "\n",
    "    def __init__(self, matrix, method='als'):\n",
    "        if (type(matrix) != np.ndarray):\n",
    "            raise Exception('ALSWrapper required matrix to be of type np.ndarray')\n",
    "\n",
    "        self.methods = ['als']\n",
    "\n",
    "        self.matrix = matrix\n",
    "\n",
    "        (self.N, self.M) = np.shape(matrix)\n",
    "\n",
    "        self.W = np.zeros([self.N, self.M])\n",
    "        mask = np.isnan(self.matrix)\n",
    "        self.W[mask == True] = 0.0\n",
    "        self.W[mask == False] = 1.0\n",
    "        self.W = self.W.astype(np.float64, copy=False)\n",
    "\n",
    "        self.matrix[mask == True] = 0.0\n",
    "\n",
    "        if (method not in self.methods):\n",
    "            print(\"The methods specified (%s) if not a valid option. Defaulting to ALS\" %method)\n",
    "            self.method = 'als'\n",
    "\n",
    "        else:\n",
    "            self.method = method\n",
    "\n",
    "    # run the ALS algorithm\n",
    "    # k is the number of factors\n",
    "    def decompose(self, k, lambda_, iterations, tol):\n",
    "\n",
    "        middleVal = 0.5 * (np.max(self.matrix) + np.min(self.matrix))\n",
    "\n",
    "        # initialize randomly\n",
    "        U = middleVal * np.random.rand(self.N, k) \n",
    "        V = middleVal * np.random.rand(k, self.M)\n",
    "\n",
    "        # fix max iterations\n",
    "        maxIter = iterations\n",
    "\n",
    "        pastError = np.inf\n",
    "        for ii in range(maxIter):\n",
    "            # first U matrix with V fixed\n",
    "            for u, Wu in enumerate(self.W):\n",
    "                left = np.linalg.pinv(np.dot(V, np.dot(np.diag(Wu), V.T)) + lambda_ * np.eye(k))\n",
    "                right = np.dot(V, np.dot(np.diag(Wu), self.matrix[u].T))\n",
    "                U[u] = np.dot(left, right).T\n",
    "\n",
    "                    #np.linalg.solve(np.dot(V, np.dot(np.diag(Wu), V.T)) + lambda_ * np.eye(k),\n",
    "                              # np.dot(V, np.dot(np.diag(Wu), self.matrix[u].T))).T\n",
    "\n",
    "            # now V matrix with U fixed\n",
    "            for i, Wi in enumerate(self.W.T):\n",
    "                left = np.linalg.pinv(np.dot(U.T, np.dot(np.diag(Wi), U)) + lambda_ * np.eye(k))\n",
    "                right = np.dot(U.T, np.dot(np.diag(Wi), self.matrix[:, i]))\n",
    "                V[:,i] = np.dot(left, right).T\n",
    "\n",
    "                #np.linalg.solve(np.dot(U.T, np.dot(np.diag(Wi), U)) + lambda_ * np.eye(k),\n",
    "                          #       np.dot(U.T, np.dot(np.diag(Wi), self.matrix[:, i])))\n",
    "            \n",
    "            # compute MSE\n",
    "            err = self.getError(self.matrix, U, V, self.W)\n",
    "\n",
    "            # break if difference is less than tol\n",
    "            deltaErr = np.abs(err - pastError)\n",
    "            if (deltaErr < tol):\n",
    "                break\n",
    "            else:\n",
    "                pastError = err\n",
    "\n",
    "            if (ii%10 == 0):\n",
    "                print(\"Iteration %d, Err = %0.4f, DeltaErr = %0.4f\" %(ii+1, pastError, deltaErr))\n",
    "\n",
    "        print('Total Iterations = %d' %(ii+1))\n",
    "        return (U,V)\n",
    "        \n",
    "\n",
    "\n",
    "    # get the matrix reconstruction using k factors and missing data\n",
    "    def reconstructMatrix(self, k, lambda_, returnMatrix=True, iterations=1000, tol=1e-6):\n",
    "\n",
    "        (Uk, Vk) = self.decompose(k, lambda_, iterations, tol)\n",
    "        if (returnMatrix == True):\n",
    "            return np.dot(Uk, Vk)\n",
    "        else:\n",
    "            return (Uk, Vk)\n",
    "\n",
    "\n",
    "    # MSE function for the ALS algorithm\n",
    "    def getError(self, Q, U, V, W):\n",
    "        return np.mean((W * (Q - np.dot(U, V)))**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "#\n",
    "# The Time Series Model based on SVD\n",
    "#\n",
    "######################################################\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class SVDModel(object):\n",
    "\n",
    "    # seriesToPredictKey:       (string) the time series of interest (key)\n",
    "    # kSingularValuesToKeep:    (int) the number of singular values to retain\n",
    "    # N:                        (int) the number of rows of the matrix for each series\n",
    "    # M:                        (int) the number of columns for the matrix for each series\n",
    "    # probObservation:          (float) the independent probability of observation of each entry in the matrix\n",
    "    # svdMethod:                (string) the SVD method to use (optional)\n",
    "    # otherSeriesKeysArray:     (array) an array of keys for other series which will be used to predict \n",
    "    # includePastDataOnly:      (Boolean) defaults to True. If this is set to False, \n",
    "    #                               the time series in 'otherSeriesKeysArray' will include the latest data point.\n",
    "    #                               Note: the time series of interest (seriesToPredictKey) will never include \n",
    "    #                               the latest data-points for prediction\n",
    "    def __init__(self, seriesToPredictKey, kSingularValuesToKeep, N, M, probObservation=1.0, svdMethod='numpy', otherSeriesKeysArray=[], includePastDataOnly=True, start = 0, TimesUpdated = 0, TimesReconstructed =0 ):\n",
    "\n",
    "        self.seriesToPredictKey = seriesToPredictKey\n",
    "        self.otherSeriesKeysArray = otherSeriesKeysArray\n",
    "        self.includePastDataOnly = includePastDataOnly\n",
    "\n",
    "        self.N = N\n",
    "        self.M = M\n",
    "        self.start = start\n",
    "        self.TimesUpdated = TimesUpdated\n",
    "        self.TimesReconstructed = TimesReconstructed\n",
    "        self.kSingularValues = kSingularValuesToKeep\n",
    "        self.svdMethod = svdMethod\n",
    "\n",
    "        self.Uk = None\n",
    "        self.Vk = None\n",
    "        self.sk = None\n",
    "        self.matrix = None\n",
    "        self.lastRowObservations = None\n",
    "        self.Ukw = None\n",
    "        self.Vkw = None\n",
    "        self.skw = None\n",
    "        self.p = probObservation\n",
    "\n",
    "        self.weights = None\n",
    "\n",
    "    # run a least-squares regression of the last row of self.matrix and all other rows of self.matrix\n",
    "    # sets and returns the weights\n",
    "    # DO NOT call directly\n",
    "    def _computeWeights(self):       \n",
    "\n",
    "        ### This is now the same as ALS\n",
    "        ## this is an expensive step because we are computing the SVD all over again \n",
    "        ## however, currently, there is no way around it since this is NOT the same matrix as the full\n",
    "        ## self.matrix, i.e. we have fewer (or just one less) rows\n",
    "\n",
    "        if (self.lastRowObservations is None):\n",
    "            raise Exception('Do not call _computeWeights() directly. It should only be accessed via class methods.')\n",
    "\n",
    "        # need to decide how to produce weights based on whether the N'th data points are to be included for the other time series or not\n",
    "        # for the seriesToPredictKey we only look at the past. For others, we could be looking at the current data point in time as well.\n",
    "        \n",
    "        matrixDim1 = (self.N * len(self.otherSeriesKeysArray)) + self.N-1\n",
    "        matrixDim2 = np.shape(self.matrix)[1]\n",
    "        eachTSRows = self.N\n",
    "\n",
    "        if (self.includePastDataOnly == False):\n",
    "            newMatrix = self.matrix[0:matrixDim1, :]\n",
    "\n",
    "        else:\n",
    "            matrixDim1 = ((self.N - 1) * len(self.otherSeriesKeysArray)) + self.N-1\n",
    "            eachTSRows = self.N - 1\n",
    "\n",
    "            newMatrix = np.zeros([matrixDim1, matrixDim2])\n",
    "\n",
    "            rowIndex = 0\n",
    "            matrixInd = 0\n",
    "\n",
    "            while (rowIndex < matrixDim1):\n",
    "                newMatrix[rowIndex: rowIndex + eachTSRows] = self.matrix[matrixInd: matrixInd +eachTSRows]\n",
    "\n",
    "                rowIndex += eachTSRows\n",
    "                matrixInd += self.N\n",
    "\n",
    "        svdMod = SVD(newMatrix, method='numpy')\n",
    "        (self.skw, self.Ukw, self.Vkw) = svdMod.reconstructMatrix(self.kSingularValues, returnMatrix=False)\n",
    "\n",
    "        newMatrixPInv = tsUtils.pInverseMatrixFromSVD(self.skw, self.Ukw, self.Vkw, probability=self.p)\n",
    "        self.weights = np.dot(newMatrixPInv.T, self.lastRowObservations.T)\n",
    "\n",
    "    # return the imputed matrix\n",
    "    def denoisedDF(self):\n",
    "        setAllKeys = set(self.otherSeriesKeysArray)\n",
    "        setAllKeys.add(self.seriesToPredictKey)\n",
    "\n",
    "        single_ts_rows = self.N\n",
    "        dataDict = {}\n",
    "        rowIndex = 0\n",
    "        for key in self.otherSeriesKeysArray:\n",
    "\n",
    "            dataDict.update({key: self.matrix[rowIndex*single_ts_rows: (rowIndex+1)*single_ts_rows, :].flatten('F')})\n",
    "            rowIndex += 1\n",
    "\n",
    "        dataDict.update({self.seriesToPredictKey: self.matrix[rowIndex*single_ts_rows: (rowIndex+1)*single_ts_rows, :].flatten('F')})\n",
    "\n",
    "        return pd.DataFrame(data=dataDict)\n",
    "\n",
    "    def denoisedTS(self, ind, range = True):\n",
    "\n",
    "        NewColsDenoised = tsUtils.matrixFromSVD(self.sk, self.Uk, self.Vk, probability=self.p).flatten(1)\n",
    "        if range:\n",
    "            assert len(ind) == 2\n",
    "            return NewColsDenoised[ind[0]:ind[1]]\n",
    "        else:\n",
    "\n",
    "            return NewColsDenoised[ind]\n",
    "\n",
    "\n",
    "    def denoisedDFNew(self,D,updateMethod = 'folding-in', missingValueFill = True):\n",
    "        assert (len(D) % self.N == 0)\n",
    "        p = len(D)/self.N\n",
    "        self.updateSVD(D,updateMethod)\n",
    "        NewColsDenoised = tsUtils.matrixFromSVD(self.sk, self.Uk, self.Vk[-p:,:], probability=self.p)\n",
    "\n",
    "        return NewColsDenoised.flatten(1)\n",
    "\n",
    "\n",
    "    # this internal method assigns the data (provided to fit()) to the class variables to help with computations\n",
    "    # if missingValueFill = True, then we will impute with the middle value\n",
    "    def _assignData(self, keyToSeriesDF, missingValueFill=True):\n",
    "\n",
    "        setAllKeys = set(self.otherSeriesKeysArray)\n",
    "        setAllKeys.add(self.seriesToPredictKey)\n",
    "\n",
    "        if (len(set(keyToSeriesDF.columns.values).intersection(setAllKeys)) != len(setAllKeys)):\n",
    "            raise Exception('keyToSeriesDF does not contain ALL keys provided in the constructor.')\n",
    "\n",
    "        if (missingValueFill == True):\n",
    "            # impute with the least informative value (middle)\n",
    "            max = np.nanmax(keyToSeriesDF)\n",
    "\n",
    "            min = np.nanmin(keyToSeriesDF)\n",
    "            diff = 0.5*(min + max)\n",
    "            keyToSeriesDF = keyToSeriesDF.fillna(value=diff)\n",
    "\n",
    "        T = self.N * self.M\n",
    "        for key in setAllKeys:\n",
    "            if (len(keyToSeriesDF[key]) < T):\n",
    "                raise Exception('All series (columns) provided must have length >= %d' %T)\n",
    "\n",
    "\n",
    "        # initialize the matrix of interest\n",
    "        single_ts_rows = self.N\n",
    "        matrix_cols = self.M\n",
    "        matrix_rows = (len(setAllKeys) * single_ts_rows)\n",
    "\n",
    "        self.matrix = np.zeros([matrix_rows, matrix_cols])\n",
    "\n",
    "        seriesIndex = 0\n",
    "        for key in self.otherSeriesKeysArray: # it is important to use the order of keys set in the model\n",
    "            self.matrix[seriesIndex*single_ts_rows: (seriesIndex+1)*single_ts_rows, :] = tsUtils.arrayToMatrix(keyToSeriesDF[key][-1*T:].values, single_ts_rows, matrix_cols)\n",
    "            seriesIndex += 1\n",
    "\n",
    "        # finally add the series of interest at the bottom\n",
    "       # tempMatrix = tsUtils.arrayToMatrix(keyToSeriesDF[self.seriesToPredictKey][-1*T:].values, self.N, matrix_cols)\n",
    "        self.matrix[seriesIndex*single_ts_rows: (seriesIndex+1)*single_ts_rows, :] = tsUtils.arrayToMatrix(keyToSeriesDF[self.seriesToPredictKey][-1*T:].values, single_ts_rows, matrix_cols)\n",
    "        \n",
    "        # set the last row of observations\n",
    "        self.lastRowObservations = copy.deepcopy(self.matrix[-1, :])\n",
    "\n",
    "\n",
    "    # keyToSeriesDictionary: (Pandas dataframe) a key-value Series (time series)\n",
    "    # Note that the keys provided in the constructor MUST all be present\n",
    "    # The values must be all numpy arrays of floats.\n",
    "    # This function sets the \"de-noised\" and imputed data matrix which can be accessed by the .matrix property\n",
    "    def fit(self, keyToSeriesDF):\n",
    "\n",
    "        # assign data to class variables\n",
    "\n",
    "        self._assignData(keyToSeriesDF, missingValueFill=True)\n",
    "        # now produce a thresholdedthresholded/de-noised matrix. this will over-write the original data matrix\n",
    "        svdMod = SVD(self.matrix, method='numpy')\n",
    "        (self.sk, self.Uk, self.Vk) = svdMod.reconstructMatrix(self.kSingularValues, returnMatrix=False)\n",
    "        self.matrix = tsUtils.matrixFromSVD(self.sk, self.Uk, self.Vk, probability=self.p)\n",
    "        # set weights\n",
    "        self._computeWeights()\n",
    "\n",
    "\n",
    "\n",
    "    def updateSVD(self,D, method = 'folding-in', missingValueFill = True):\n",
    "        assert (len(D) % self.N == 0)\n",
    "        if (missingValueFill == True):\n",
    "            # impute with the least informative value (middle)\n",
    "            max = np.nanmax(D)\n",
    "            if np.isnan(max): max = 0\n",
    "            min = np.nanmin(D)\n",
    "            if np.isnan(min): min = 0\n",
    "            diff = 0.5*(min + max)\n",
    "            D[np.isnan(D)] = diff\n",
    "\n",
    "        D = D.reshape([self.N,int(len(D)/self.N)])\n",
    "\n",
    "        assert D.shape[0] == self.N\n",
    "        assert D.shape[1] <= D.shape[0]\n",
    "        if method == 'UP':\n",
    "            self.Uk, self.sk, self.Vk = tsUtils.updateSVD2(D, self.Uk, self.sk, self.Vk)\n",
    "            self.M = self.Vk.shape[0]\n",
    "            self.Ukw, self.skw, self.Vkw = tsUtils.updateSVD2(D[:-1,:], self.Ukw, self.skw, self.Vkw)\n",
    "        elif method == 'folding-in':\n",
    "            self.Uk, self.sk, self.Vk = tsUtils.updateSVD(D, self.Uk, self.sk ,self.Vk )\n",
    "            self.M = self.Vk.shape[0]\n",
    "            self.Ukw, self.skw, self.Vkw = tsUtils.updateSVD(D[:-1, :], self.Ukw, self.skw, self.Vkw)\n",
    "        # elif method == 'Full':\n",
    "        #     raise ValueError\n",
    "        #     self.matrix = np.concatenate((self.matrix,D),1)\n",
    "        #     U, S, V = np.linalg.svd(self.matrix, full_matrices=False)\n",
    "        #     self.sk = S[0:self.kSingularValues]\n",
    "        #     self.Uk = U[:, 0:self.kSingularValues]\n",
    "        #     self.Vk = V[0:self.kSingularValues,:]\n",
    "        #     self.Vk = self.Vk.T\n",
    "        #     self.M = self.Vk.shape[0]\n",
    "        else:\n",
    "            raise ValueError\n",
    "        self.TimesUpdated +=1\n",
    "\n",
    "        newMatrixPInv = tsUtils.pInverseMatrixFromSVD(self.skw, self.Ukw, self.Vkw, probability=self.p)\n",
    "        self.lastRowObservations = np.append(self.lastRowObservations,D[-1,:])\n",
    "        self.weights = np.dot(newMatrixPInv.T, self.lastRowObservations.T)\n",
    "\n",
    "\n",
    "\n",
    "    # otherKeysToSeriesDFNew:     (Pandas dataframe) needs to contain all keys provided in the model;\n",
    "    #                           If includePastDataOnly was set to True (default) in the model, then:\n",
    "    #                               each series/array MUST be of length >= self.N - 1\n",
    "    #                               If longer than self.N - 1, then the most recent self.N - 1 points will be used\n",
    "    #                           If includePastDataOnly was set to False in the model, then:\n",
    "    #                               all series/array except seriesToPredictKey MUST be of length >= self.N (i.e. includes the current), \n",
    "    #                               If longer than self.N, then the most recent self.N points will be used\n",
    "    #\n",
    "    # predictKeyToSeriesDFNew:   (Pandas dataframe) needs to contain the seriesToPredictKey and self.N - 1 points past points.\n",
    "    #                           If more points are provided, the most recent self.N - 1 points are selected.   \n",
    "    #\n",
    "    # bypassChecks:         (Boolean) if this is set to True, then it is the callee's responsibility to provide\n",
    "    #                           all required series of appropriate lengths (see above).\n",
    "    #                           It is advised to leave this set to False (default).         \n",
    "    def predict(self, otherKeysToSeriesDFNew, predictKeyToSeriesDFNew, bypassChecks=False):\n",
    "\n",
    "        nbrPointsNeeded = self.N - 1\n",
    "        if (self.includePastDataOnly == False):\n",
    "            nbrPointsNeeded = self.N\n",
    "\n",
    "        if (bypassChecks == False):\n",
    "\n",
    "            if (self.weights is None):\n",
    "                raise Exception('Before predict() you need to call \"fit()\" on the model.')\n",
    "\n",
    "            if (len(set(otherKeysToSeriesDFNew.columns.values).intersection(set(self.otherSeriesKeysArray))) < len(set(self.otherSeriesKeysArray))):\n",
    "                raise Exception('keyToSeriesDFNew does not contain ALL keys provided in the constructor.')\n",
    "\n",
    "            for key in self.otherSeriesKeysArray:\n",
    "                points = len(otherKeysToSeriesDFNew[key])\n",
    "                if (points < nbrPointsNeeded):\n",
    "                    raise Exception('Series (%s) must have length >= %d' %(key, nbrPointsNeeded))\n",
    "\n",
    "            points = len(predictKeyToSeriesDFNew[self.seriesToPredictKey])\n",
    "            if (points < self.N - 1):\n",
    "                raise Exception('Series (%s) must have length >= %d' %(self.seriesToPredictKey, self.N - 1))\n",
    "\n",
    "        newDataArray = np.zeros((len(self.otherSeriesKeysArray) * nbrPointsNeeded) + self.N - 1)\n",
    "        indexArray = 0\n",
    "        for key in self.otherSeriesKeysArray:\n",
    "            newDataArray[indexArray: indexArray + nbrPointsNeeded] = otherKeysToSeriesDFNew[key][-1*nbrPointsNeeded: ].values\n",
    "\n",
    "            indexArray += nbrPointsNeeded\n",
    "\n",
    "        # at last fill in the time series of interest\n",
    "        newDataArray[indexArray:] = predictKeyToSeriesDFNew[self.seriesToPredictKey][-1*(self.N - 1):].values\n",
    "\n",
    "        # dot product\n",
    "        return np.dot(self.weights, newDataArray)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "#\n",
    "# The Time Series Model based on ALS\n",
    "#\n",
    "######################################################\n",
    "\n",
    "class ALSModel(SVDModel):\n",
    "\n",
    "    # seriesToPredictKey:       (string) the time series of interest (key)\n",
    "    # kFactors:    \t\t\t\t(int) number of factors (similar to the kSingularValues of the parent class)\n",
    "    # N:                        (int) the number of rows of the matrix for each series\n",
    "    # M:                        (int) the number of columns for the matrix for each series\n",
    "    # probObservation:          (float) the independent probability of observation of each entry in the matrix\n",
    "    # otherSeriesKeysArray:     (array) an array of keys for other series which will be used to predict \n",
    "    # includePastDataOnly:      (Boolean) defaults to True. If this is set to False, \n",
    "    #                               the time series in 'otherSeriesKeysArray' will include the latest data point.\n",
    "    #                               Note: the time series of interest (seriesToPredictKey) will never include \n",
    "    #                               the latest data-points for prediction\n",
    "    def __init__(self, seriesToPredictKey, kFactors, N, M, probObservation=1.0, otherSeriesKeysArray=[], includePastDataOnly=True):\n",
    "\n",
    "        super(ALSModel, self).__init__(seriesToPredictKey, kFactors, N, M, probObservation=probObservation, svdMethod='numpy', otherSeriesKeysArray=otherSeriesKeysArray, includePastDataOnly=includePastDataOnly)\n",
    "\n",
    "    # run a least-squares regression of the last row of self.matrix and all other rows of self.matrix\n",
    "    # sets and returns the weights\n",
    "    # DO NOT call directly\n",
    "    def _computeWeights(self):   \n",
    "        if (self.lastRowObservations is None):\n",
    "            raise Exception('Do not call _computeWeights() directly. It should only be accessed via class methods.')\n",
    "\n",
    "        # need to decide how to produce weights based on whether the N'th data points are to be included for the other time series or not\n",
    "        # for the seriesToPredictKey we only look at the past. For others, we could be looking at the current data point in time as well.\n",
    "        \n",
    "        matrixDim1 = (self.N * len(self.otherSeriesKeysArray)) + self.N-1\n",
    "        matrixDim2 = np.shape(self.matrix)[1]\n",
    "        eachTSRows = self.N\n",
    "\n",
    "        if (self.includePastDataOnly == False):\n",
    "        \tnewMatrix = self.matrix[0:matrixDim1, :]\n",
    "    \n",
    "        else:\n",
    "            matrixDim1 = ((self.N - 1) * len(self.otherSeriesKeysArray)) + self.N-1\n",
    "            eachTSRows = self.N - 1\n",
    "\n",
    "            newMatrix = np.zeros([matrixDim1, matrixDim2])\n",
    "\n",
    "            rowIndex = 0\n",
    "            matrixInd = 0\n",
    "            print(eachTSRows)\n",
    "            while (rowIndex < matrixDim1):\n",
    "            \tnewMatrix[rowIndex: rowIndex + eachTSRows] = self.matrix[matrixInd: matrixInd +eachTSRows]\n",
    "            \trowIndex += eachTSRows\n",
    "            \tmatrixInd += self.N\n",
    "        self.weights = np.dot(np.linalg.pinv(newMatrix).T, self.lastRowObservations.T)\n",
    "\n",
    "\n",
    "\t# keyToSeriesDictionary: (Pandas dataframe) a key-value Series (time series)\n",
    "    # Same as the parent class (SVDModel)\n",
    "    def fit(self, keyToSeriesDF):\n",
    "\n",
    "        # assign data to class variables\n",
    "        super(ALSModel, self)._assignData(keyToSeriesDF, missingValueFill=False)\n",
    "\n",
    "        self.max = np.nanmax(self.matrix)\n",
    "        self.min = np.nanmin(self.matrix)\n",
    "\n",
    "        # now use ALS to produce an estimated matrix\n",
    "        alsMod = ALS(self.matrix, method='als')\n",
    "        (U, V) = alsMod.reconstructMatrix(self.kSingularValues, 0.0, returnMatrix=False, tol=1e-9)\n",
    "\n",
    "        self.matrix = np.dot(U, V)\n",
    "\n",
    "        self.matrix[self.matrix > self.max] = self.max\n",
    "        self.matrix[self.matrix < self.min] = self.min\n",
    "\n",
    "        # we need to assign some values to the lastRowObservations where there are still NaNs\n",
    "        # impute those with the ALS-estimated/iputed values\n",
    "        for i in range(0, len(self.lastRowObservations)):\n",
    "        \tif (np.isnan(self.lastRowObservations[i])):\n",
    "        \t\tself.lastRowObservations[i] = self.matrix[-1, i]\n",
    "\n",
    "        # set weights (same as the parent class now that we have the SVD of the ALS-estimated matrix)\n",
    "        self._computeWeights()\n",
    "\t\n",
    "\t# return the imputed matrix, same as the parent class (SVDModel)\n",
    "    def denoisedDF(self):\n",
    "\n",
    "    \treturn super(ALSModel, self).denoisedDF()\n",
    "\n",
    "\t# same params as the predict() method of the parent class (SVDModel)       \n",
    "    def predict(self, otherKeysToSeriesDFNew, predictKeyToSeriesDFNew, bypassChecks=False):\n",
    "\n",
    "    \treturn super(ALSModel, self).predict(otherKeysToSeriesDFNew, predictKeyToSeriesDFNew, bypassChecks)\n",
    "\n",
    "    def updateSVD(self, D):\n",
    "        return super(ALSModel, self).updateSVD(self, D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
